{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5b8f9b",
   "metadata": {},
   "source": [
    "# Statistical Analysis for Chicago crime dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3755c80",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gdown dask pyarrow\n",
    "# import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761c3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib for datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up views\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d23d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # import lib for loading the dataset \n",
    "# import gdown\n",
    "# import zipfile\n",
    "\n",
    "# # Importing the dataset from google drive\n",
    "# raw_link = \"_https://www.kaggle.com/datasets/utkarshx27/crimes-2001-to-present?resource=download_\"\n",
    "# id = \"1ib1PWK_3oaaSfThqfnfSoPZq7vA1g33X\"\n",
    "# file_path = \"crime.zip\"\n",
    "\n",
    "# # Loading the dataset\n",
    "# gdown.download(f\"https://drive.google.com/uc?id={id}\",file_path, quiet=False)\n",
    "\n",
    "# uncomment this code to download the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee085694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib for loading the dataset \n",
    "\n",
    "import kagglehub\n",
    "from pathlib import Path\n",
    "\n",
    "# Step 1: Download the dataset from Kaggle using kagglehub\n",
    "# Dataset: https://www.kaggle.com/datasets/utkarshx27/crimes-2001-to-present\n",
    "\n",
    "dataset_path = Path(kagglehub.dataset_download(\"utkarshx27/crimes-2001-to-present\"))\n",
    "\n",
    "print(\"Dataset Path\", dataset_path)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Define the path to the actual CSV file\n",
    "csv_file = dataset_path / \"Crimes_-_2001_to_Present.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e645a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = r\"C:\\Users\\Noimot\\.cache\\kagglehub\\datasets\\utkarshx27\\crimes-2001-to-present\\versions\\1\\Crimes_-_2001_to_Present.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df763c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 416. MiB for an array with shape (7, 7784664) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m crime_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1965\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1966\u001b[39m         new_col_dict = col_dict\n\u001b[32m-> \u001b[39m\u001b[32m1968\u001b[39m     df = \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1975\u001b[39m     \u001b[38;5;28mself\u001b[39m._currow += new_rows\n\u001b[32m   1976\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    149\u001b[39m axes = [columns, index]\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefs\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[39m, in \u001b[36mcreate_block_manager_from_column_arrays\u001b[39m\u001b[34m(arrays, axes, consolidate, refs)\u001b[39m\n\u001b[32m   2142\u001b[39m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[32m0\u001b[39m].shape, axes, e)\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[32m-> \u001b[39m\u001b[32m2144\u001b[39m     \u001b[43mmgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[39m, in \u001b[36mBlockManager._consolidate_inplace\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1783\u001b[39m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[32m   1784\u001b[39m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[32m   1785\u001b[39m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[32m   1786\u001b[39m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[32m   1787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_consolidated():\n\u001b[32m-> \u001b[39m\u001b[32m1788\u001b[39m         \u001b[38;5;28mself\u001b[39m.blocks = \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m         \u001b[38;5;28mself\u001b[39m._is_consolidated = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1790\u001b[39m         \u001b[38;5;28mself\u001b[39m._known_consolidated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[39m, in \u001b[36m_consolidate\u001b[39m\u001b[34m(blocks)\u001b[39m\n\u001b[32m   2267\u001b[39m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] = []\n\u001b[32m   2268\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[32m-> \u001b[39m\u001b[32m2269\u001b[39m     merged_blocks, _ = \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2270\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[32m   2271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2272\u001b[39m     new_blocks = extend_blocks(merged_blocks, new_blocks)\n\u001b[32m   2273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2294\u001b[39m, in \u001b[36m_merge_blocks\u001b[39m\u001b[34m(blocks, dtype, can_consolidate)\u001b[39m\n\u001b[32m   2287\u001b[39m new_values: ArrayLike\n\u001b[32m   2289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[32m0\u001b[39m].dtype, np.dtype):\n\u001b[32m   2290\u001b[39m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[32m   2291\u001b[39m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[32m   2292\u001b[39m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[32m   2293\u001b[39m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2294\u001b[39m     new_values = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   2295\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2296\u001b[39m     bvals = [blk.values \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Noimot\\Desktop\\Module_2_task_submissions\\venv\\Lib\\site-packages\\numpy\\_core\\shape_base.py:292\u001b[39m, in \u001b[36mvstack\u001b[39m\u001b[34m(tup, dtype, casting)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    291\u001b[39m     arrs = (arrs,)\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 416. MiB for an array with shape (7, 7784664) and data type float64"
     ]
    }
   ],
   "source": [
    "# crime_data = pd.read_csv(csv_file, low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc245836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting and listing the files in the zipped dataset\n",
    "# with zipfile.ZipFile(file_path, \"r\") as z:\n",
    "#     # List files\n",
    "#     print(z.namelist()) \n",
    "#     z.extractall(\"crime_dataset\")\n",
    "\n",
    "\n",
    "# Commenting this out because I have read/loaded the dataset to my workspace.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c7b62",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Define data types to reduce memory usage\n",
    "dtype_dict = {\n",
    "    'ID' : 'Int32',\n",
    "    'Case Number': 'string',\n",
    "    'Block': 'string',\n",
    "    'IUCR': 'category',\n",
    "    'Primary Type': 'category',\n",
    "    'Description': 'category',\n",
    "    'Location Description': 'category',\n",
    "    'Arrest': 'boolean',\n",
    "    'Domestic': 'boolean',\n",
    "    'Beat': 'Int64',\n",
    "    'District': 'Int64',\n",
    "    'Ward': 'Int64',\n",
    "    'Community Area': 'Int64',\n",
    "    'FBI Code': 'category',\n",
    "    'X Coordinate': 'float32',\n",
    "    'Y Coordinate': 'float32',\n",
    "    'Year': 'float64',\n",
    "    'Latitude': 'float32',\n",
    "    'Longitude': 'float32',\n",
    "    'Location': 'string'\n",
    "}\n",
    "\n",
    "# Loading the dataset with dask to handle the huge csv files\n",
    "crime_data = pd.read_csv(csv_file,dtype=dtype_dict, parse_dates=['Date', 'Updated On'],date_format=\"%m/%d/%y %I:%M:%S %p\",low_memory=False,keep_default_na=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print the first five rows\n",
    "crime_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the dataset\n",
    "crime_dataset = crime_data.copy()\n",
    "crime_dataset.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f5eb8",
   "metadata": {},
   "source": [
    "# Preliminary data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date to datetime\n",
    "crime_dataset['Date'] = pd.to_datetime(crime_dataset['Date'])\n",
    "crime_dataset['Date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data type\n",
    "crime_data_type = crime_dataset.dtypes\n",
    "print(\"Data type\\n:\", crime_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd63ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the columns \n",
    "crime_data_cols = pd.read_csv('crime_dataset/Crimes_-_2001_to_Present.csv', nrows=5)\n",
    "print(crime_data_cols.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns (removing whitespaces, convert to lower case and replace \" \" with \",\") \n",
    "crime_dataset = crime_data.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"))\n",
    "first_five_rows = crime_dataset.head()\n",
    "print(\"First five rows in the dataset:\\n\", first_five_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d16259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset for missing values\n",
    "crime_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d593b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset for duplicated values\n",
    "duplicated = crime_dataset.duplicated().sum()\n",
    "print(\"Duplicated values:\", duplicated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd9bba0",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the year column to Integer\n",
    "crime_dataset['year'] = crime_dataset['year'].astype('Int64')\n",
    "\n",
    "# Checking the number of years in the dataset\n",
    "crime_dataset_years_no = crime_dataset['year'].nunique()\n",
    "print(f\"Chicago crime dataset for {crime_dataset_years_no} years\\n\")\n",
    "\n",
    "# Checking the years in the dataset\n",
    "crime_dataset_years = crime_dataset['year'].unique()\n",
    "print(f\"The years in the dataset are\\n{crime_dataset_years}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88995db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the size of the dataset\n",
    "crime_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967dba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data type\n",
    "crime_dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b823e4",
   "metadata": {},
   "source": [
    "# Descriptive Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Statistical summary of the data\n",
    "# fetching numeric columns only\n",
    "\n",
    "crime_data_numeric = crime_dataset.select_dtypes(include=['number']).columns\n",
    "crime_data_numeric_summary = crime_dataset[crime_data_numeric].describe()\n",
    "print(\"\\nSummary Statistics:\\n\", crime_data_numeric_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the year, month and day from the dataset\n",
    "crime_dataset['date'] = pd.to_datetime(crime_dataset['date'])\n",
    "crime_dataset['year'] = crime_dataset['date'].dt.year\n",
    "crime_dataset['month'] = crime_dataset['date'].dt.month_name()\n",
    "crime_dataset['day'] = crime_dataset['date'].dt.day_name()\n",
    "\n",
    "crime_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting the index using date\n",
    "# crime_index =crime_dataset.set_index('primary_type', inplace=True)\n",
    "# crime_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b044c87",
   "metadata": {},
   "source": [
    "# Certain Crimes in the last ten Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa32e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the crime for the last ten years\n",
    "crime_dataset_ten_yrs = crime_dataset[crime_dataset['year'] >= 2013]\n",
    "crime_dataset_ten_yrs.tail(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of crimes rate in the last ten years\n",
    "crime_ten_yrs = crime_dataset_ten_yrs['primary_type'].nunique()\n",
    "print(f\"There were {crime_ten_yrs} crimes recorded in the last ten years\\n\")\n",
    "\n",
    "# # Checking the type of crimes rate in the last ten years\n",
    "type_crime_ten_yrs = crime_dataset_ten_yrs['primary_type'].unique()\n",
    "print(f\"The types of crimes in the last ten years:\\n {type_crime_ten_yrs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the crimes in the last ten years\n",
    "ten_yrs_crimes = crime_dataset_ten_yrs.index.value_counts().head(100)\n",
    "ten_yrs_crimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003b212",
   "metadata": {},
   "source": [
    "`Data Visualization for all the Crimes recorded in the last ten years`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a barchart for the crimes committed in the last ten years\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(ten_yrs_crimes.index, ten_yrs_crimes.values, color='red')\n",
    "plt.xlabel('Crimes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Crimes committed in the last ten Years(2013-2023)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e11c4a",
   "metadata": {},
   "source": [
    "# Theft in the last ten years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the theft in the last ten years\n",
    "theft = crime_dataset_ten_yrs.loc['THEFT']\n",
    "print(f\"Number of theft recorded from 2013-2023): {theft}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping theft by year for the last ten years\n",
    "theft_ten_yrs = theft.groupby('year').size().sort_values(ascending=True)\n",
    "print(f\"Theft recorded from 2013-2023:\\n {theft_ten_yrs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the theft recorded over the last ten years using barchart in Pandas\n",
    "theft_ten_yrs.plot(kind='bar', xlabel='Year', ylabel='Frequency', title=\"Theft recorded in the last ten Years(2013-2023)\", color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f27af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the Theft by location over the last ten years\n",
    "theft_by_location = theft.groupby('block')['year'].size().sort_values(ascending=True)\n",
    "theft_by_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70df14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the theft recorded over the last ten years using barchart in Pandas\n",
    "# theft_by_location.plot(kind='bar', xlabel='Year', ylabel='Frequency', title=\"Theft recorded in the last ten Years(2013-2023)\", color='black')\n",
    "# Plotting a barchart for the crimes committed in the last ten years\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(theft_by_location.index, theft_by_location.values, color='red')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Year')\n",
    "plt.title(\"Theft recorded by location in the last ten Years(2013-2023)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
